{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import gym\nimport matplotlib as plt\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport time","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class simpleLayer(tf.keras.layers.Layer):\n    def __init__(self,dense_units=7,last_layer=False):\n        super(simpleLayer, self).__init__()\n        self.dense_units = dense_units\n        self.batchnorm = tf.keras.layers.BatchNormalization(axis= -1) # channell first\n        self.last = last_layer\n        if not self.last:\n            self.dropout = tf.keras.layers.Dropout(0.3)\n    \n    def build(self,input_shape):\n        self.dense = tf.keras.layers.Dense(self.dense_units,input_shape = input_shape)\n        \n        \n    def call(self, input):\n        out = self.dense(input)\n        #out = self.batchnorm(out)\n        if not self.last:\n            out = self.dropout(out)\n        return out","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef shuffle(list1, list2):\n    temp = zip(list1, list2)\n    np.random.shuffle(temp)\n    a, b = zip(*temp)\n    return a ,b","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class actorNet(tf.keras.Model):\n    def __init__(self):\n        super(actorNet, self).__init__()\n        self.layer1 = simpleLayer()\n        self.layer2 = simpleLayer()\n        self.layer3 = simpleLayer(last_layer=True)\n        self.dense = tf.keras.layers.Dense(2, activation = self.myActivation)\n    \n    def call(self, input):\n        x = self.layer1(input)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.dense(x)\n        return x\n    \n    def myActivation(self,x):\n        return tf.keras.activations.softmax(x,axis=-1)\n    \n    \n    def ppoLoss(self, y_true, y_pred, advantage, old_prediction):\n        ENTROPY_LOSS = 5e-3\n        LOSS_CLIPPING = 0.2\n        prob = tf.keras.backend.sum(y_true * y_pred, axis=-1)\n        prob = tf.dtypes.cast(prob, tf.float32)\n        old_prob = tf.keras.backend.sum(y_true * old_prediction, axis=-1)\n        old_prob = tf.dtypes.cast(old_prob, tf.float32)\n        r = prob/(old_prob + 1e-10)\n        return -tf.keras.backend.mean(tf.keras.backend.minimum(r * advantage, tf.keras.backend.clip(r, min_value=1 - LOSS_CLIPPING, max_value=1 + LOSS_CLIPPING) * advantage) + ENTROPY_LOSS * -(prob * tf.keras.backend.log(prob + 1e-10)))\n        \n    \n    \n    def learn(self, observe, action, advantage, old_prediction, epochs, batch, shuffle):\n        self.optimaizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n        for epoch in range(epochs):\n            batch_observe = observe[batch*epoch:batch*(epoch+1)]\n            batch_action = action[batch*epoch:batch*(epoch+1)]\n            if shuffle is True:\n                batch_observe, batch_action = shuffle(batch_observe, batch_action)\n            print(\"Start of epoch %d\" % (epoch,))\n            for step, (obs_batch_train, act_batch_train) in enumerate(zip(batch_observe,batch_action)):\n                with tf.GradientTape() as tape:\n                    print(obs_batch_train.shape)\n                    pred_action = self.call(obs_batch_train)\n                    loss = self.ppoLoss(act_batch_train,pred_action,advantage, old_prediction )\n                    \n\n                print(\"the model loss is :%d\" % loss)\n                grads = tape.gradient(loss, self.trainable_weights)\n                self.optimaizer.apply_gradients(zip(grads, self.trainable_weights))\n","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class criticNet(tf.keras.Model):\n    def __init__(self):\n        super(criticNet, self).__init__()\n        self.layer1 = simpleLayer()\n        self.layer2 = simpleLayer()\n        self.layer3 = simpleLayer(last_layer=True)\n        self.dense = tf.keras.layers.Dense(1, activation = self.myActivation)\n    def call(self, input):\n        x = self.layer1(input)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.dense(x)\n        return x\n    def myActivation(self,x):\n        return tf.keras.activations.linear(x)\n    \n    def learn(self, observe, reward, epochs, batch ,shuffle):\n        \n        self.optimaizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n        for i in range(epochs):\n            batch_observe = observe[batch*i:batch*(i+1)]\n            batch_reward = reward[batch*i:batch*(i+1)]\n            if shuffle is True:\n                batch_observe, batch_reward = shuffle(batch_observe, batch_reward)\n            for j, (batch_observe_train, batch_reward_train) in enumerate(zip(batch_observe,batch_reward)):\n                with tf.GradientTape() as tape:\n                    print(batch_observe_train.shape)\n                    pred_reward = self.call(batch_observe_train)\n                    loss = tf.keras.losses.MSE(batch_reward_train, pred_reward)\n                print(\"the model loss is :%d\" % loss)\n                grads = tape.gradient(loss, self.trainable_weights)\n                self.optimaizer.apply_gradients(zip(grads, self.trainable_weights))\n                ","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Gamerecord():\n    def __init__(self):\n        self.observations = []\n        self.actions = []\n        self.actionPredictions = []\n        self.reward_steps = []\n        self.reward_total = []\n        self.first_epoch_index = 0\n    \n    def add_reward(self, reward,done, gamma=0.9):\n        self.reward_steps.append(reward)\n        self.reward_total.append(reward)\n        list_size = len(self.reward_total)\n        if done is True:\n            self.first_epoch_index = list_size - 1\n        power = 1\n        for i in range(list_size-2, self.first_epoch_index-1, -1):\n            self.reward_total[i] += (gamma**power)*reward\n            power += 1\n            \n    def reset(self):\n        self.observations = []\n        self.actions = []\n        self.actionPredictions = []\n        self.reward_steps = []\n        self.reward_total = []\n            ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = np.array(env.observation_space.sample()).reshape(1,4)\nmodel = actorNet()\nx = model(temp)\nmodel.summary()\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 256\nEPISODES = 10\nEPOCHS = 10\nBATCH_SIZE = 256\n\nclass Agent():\n    def __init__(self):\n        self.actionNet = actorNet()\n        self.criticalNet = criticNet()\n        self.env = gym.make('CartPole-v0')\n        self.episode = 0\n        self.observation = self.env.reset()\n        self.records = Gamerecord()\n        self.gradient_steps = 0\n\n        \n    def reset_env(self):\n        self.episode += 1\n        self.observation = self.env.reset()\n        \n    def choose_action(self):\n        p = self.actionNet.predict(self.observation.reshape(1, 4))\n        action = np.random.choice(2, p=np.nan_to_num(p[0]))\n        action_matrix = np.zeros(2)\n        action_matrix[action] = 1\n        return action, action_matrix, p   \n    \n    \n    \n    \n    \n    def get_experiance(self):\n        \n        while len(self.records.observations) < BUFFER_SIZE:\n          \n            print(\"processing :\", len(self.records.observations),\"\\n\")\n            action, action_matrix, predicted_action = self.choose_action()\n            observation, reward, done, info = self.env.step(action)\n            \n            self.records.observations.append(self.observation)\n            self.records.actions.append(action_matrix)\n            self.records.actionPredictions.append(predicted_action)\n            self.records.add_reward(reward, done)\n            \n            self.observation = observation\n\n            if done:\n                self.reset_env()\n\n        obs, action, pred, reward = np.array(self.records.observations).reshape(-1,1,4), np.array(self.records.actions), np.array(self.records.actionPredictions).reshape(-1,1,2), np.array(self.records.reward_total).reshape(-1,1,1)\n        return obs, action, pred, reward\n    \n    def learn(self):\n        \n        while self.episode < EPISODES:\n            obs, action, pred, reward = self.get_experiance()\n            obs, action, pred, reward = obs[:BUFFER_SIZE], action[:BUFFER_SIZE], pred[:BUFFER_SIZE], reward[:BUFFER_SIZE]\n            old_prediction = pred\n            \n            pred_values = self.criticalNet.predict(obs)\n            advantage = reward - pred_values\n            \n            self.actionNet.learn(obs, action, advantage, old_prediction, EPOCHS, BATCH_SIZE, shuffle=False)\n            self.criticalNet.learn(obs, reward, EPOCHS, BATCH_SIZE, shuffle=False)\n\n            self.gradient_steps += 1\n    \n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    ag = Agent()\n    ag.learn()","execution_count":24,"outputs":[{"output_type":"stream","text":"processing : 0 \n\nprocessing : 1 \n\nprocessing : 2 \n\nprocessing : 3 \n\nprocessing : 4 \n\nprocessing : 5 \n\nprocessing : 6 \n\nprocessing : 7 \n\nprocessing : 8 \n\nprocessing : 9 \n\nprocessing : 10 \n\nprocessing : 11 \n\nprocessing : 12 \n\nprocessing : 13 \n\nprocessing : 14 \n\nprocessing : 15 \n\nprocessing : 16 \n\nprocessing : 17 \n\nprocessing : 18 \n\nprocessing : 19 \n\nprocessing : 20 \n\nprocessing : 21 \n\nprocessing : 22 \n\nprocessing : 23 \n\nprocessing : 24 \n\nprocessing : 25 \n\nprocessing : 26 \n\nprocessing : 27 \n\nprocessing : 28 \n\nprocessing : 29 \n\nprocessing : 30 \n\nprocessing : 31 \n\nprocessing : 32 \n\nprocessing : 33 \n\nprocessing : 34 \n\nprocessing : 35 \n\nprocessing : 36 \n\nprocessing : 37 \n\nprocessing : 38 \n\nprocessing : 39 \n\nprocessing : 40 \n\nprocessing : 41 \n\nprocessing : 42 \n\nprocessing : 43 \n\nprocessing : 44 \n\nprocessing : 45 \n\nprocessing : 46 \n\nprocessing : 47 \n\nprocessing : 48 \n\nprocessing : 49 \n\nprocessing : 50 \n\nprocessing : 51 \n\nprocessing : 52 \n\nprocessing : 53 \n\nprocessing : 54 \n\nprocessing : 55 \n\nprocessing : 56 \n\nprocessing : 57 \n\nprocessing : 58 \n\nprocessing : 59 \n\nprocessing : 60 \n\nprocessing : 61 \n\nprocessing : 62 \n\nprocessing : 63 \n\nprocessing : 64 \n\nprocessing : 65 \n\nprocessing : 66 \n\nprocessing : 67 \n\nprocessing : 68 \n\nprocessing : 69 \n\nprocessing : 70 \n\nprocessing : 71 \n\nprocessing : 72 \n\nprocessing : 73 \n\nprocessing : 74 \n\nprocessing : 75 \n\nprocessing : 76 \n\nprocessing : 77 \n\nprocessing : 78 \n\nprocessing : 79 \n\nprocessing : 80 \n\nprocessing : 81 \n\nprocessing : 82 \n\nprocessing : 83 \n\nprocessing : 84 \n\nprocessing : 85 \n\nprocessing : 86 \n\nprocessing : 87 \n\nprocessing : 88 \n\nprocessing : 89 \n\nprocessing : 90 \n\nprocessing : 91 \n\nprocessing : 92 \n\nprocessing : 93 \n\nprocessing : 94 \n\nprocessing : 95 \n\nprocessing : 96 \n\nprocessing : 97 \n\nprocessing : 98 \n\nprocessing : 99 \n\nprocessing : 100 \n\nprocessing : 101 \n\nprocessing : 102 \n\nprocessing : 103 \n\nprocessing : 104 \n\nprocessing : 105 \n\nprocessing : 106 \n\nprocessing : 107 \n\nprocessing : 108 \n\nprocessing : 109 \n\nprocessing : 110 \n\nprocessing : 111 \n\nprocessing : 112 \n\nprocessing : 113 \n\nprocessing : 114 \n\nprocessing : 115 \n\nprocessing : 116 \n\nprocessing : 117 \n\nprocessing : 118 \n\nprocessing : 119 \n\nprocessing : 120 \n\nprocessing : 121 \n\nprocessing : 122 \n\nprocessing : 123 \n\nprocessing : 124 \n\nprocessing : 125 \n\nprocessing : 126 \n\nprocessing : 127 \n\nprocessing : 128 \n\nprocessing : 129 \n\nprocessing : 130 \n\nprocessing : 131 \n\nprocessing : 132 \n\nprocessing : 133 \n\nprocessing : 134 \n\nprocessing : 135 \n\nprocessing : 136 \n\nprocessing : 137 \n\nprocessing : 138 \n\nprocessing : 139 \n\nprocessing : 140 \n\nprocessing : 141 \n\nprocessing : 142 \n\nprocessing : 143 \n\nprocessing : 144 \n\nprocessing : 145 \n\nprocessing : 146 \n\nprocessing : 147 \n\nprocessing : 148 \n\nprocessing : 149 \n\nprocessing : 150 \n\nprocessing : 151 \n\nprocessing : 152 \n\nprocessing : 153 \n\nprocessing : 154 \n\nprocessing : 155 \n\nprocessing : 156 \n\nprocessing : 157 \n\nprocessing : 158 \n\nprocessing : 159 \n\nprocessing : 160 \n\nprocessing : 161 \n\nprocessing : 162 \n\nprocessing : 163 \n\nprocessing : 164 \n\nprocessing : 165 \n\nprocessing : 166 \n\nprocessing : 167 \n\nprocessing : 168 \n\nprocessing : 169 \n\nprocessing : 170 \n\nprocessing : 171 \n\nprocessing : 172 \n\nprocessing : 173 \n\nprocessing : 174 \n\nprocessing : 175 \n\nprocessing : 176 \n\nprocessing : 177 \n\nprocessing : 178 \n\nprocessing : 179 \n\nprocessing : 180 \n\nprocessing : 181 \n\nprocessing : 182 \n\nprocessing : 183 \n\nprocessing : 184 \n\nprocessing : 185 \n\nprocessing : 186 \n\nprocessing : 187 \n\nprocessing : 188 \n\nprocessing : 189 \n\nprocessing : 190 \n\nprocessing : 191 \n\nprocessing : 192 \n\nprocessing : 193 \n\nprocessing : 194 \n\nprocessing : 195 \n\nprocessing : 196 \n\nprocessing : 197 \n\nprocessing : 198 \n\nprocessing : 199 \n\nprocessing : 200 \n\nprocessing : 201 \n\nprocessing : 202 \n\nprocessing : 203 \n\nprocessing : 204 \n\nprocessing : 205 \n\nprocessing : 206 \n\nprocessing : 207 \n\nprocessing : 208 \n\nprocessing : 209 \n\nprocessing : 210 \n\nprocessing : 211 \n\nprocessing : 212 \n\nprocessing : 213 \n\nprocessing : 214 \n\nprocessing : 215 \n\nprocessing : 216 \n\nprocessing : 217 \n\nprocessing : 218 \n\nprocessing : 219 \n\nprocessing : 220 \n\nprocessing : 221 \n\nprocessing : 222 \n\nprocessing : 223 \n\nprocessing : 224 \n\nprocessing : 225 \n\nprocessing : 226 \n\nprocessing : 227 \n\nprocessing : 228 \n\nprocessing : 229 \n\nprocessing : 230 \n\nprocessing : 231 \n\nprocessing : 232 \n\nprocessing : 233 \n\nprocessing : 234 \n\nprocessing : 235 \n\nprocessing : 236 \n\nprocessing : 237 \n\nprocessing : 238 \n\nprocessing : 239 \n\nprocessing : 240 \n\nprocessing : 241 \n\nprocessing : 242 \n\nprocessing : 243 \n\nprocessing : 244 \n\nprocessing : 245 \n\nprocessing : 246 \n\nprocessing : 247 \n\nprocessing : 248 \n\nprocessing : 249 \n\nprocessing : 250 \n\nprocessing : 251 \n\nprocessing : 252 \n\nprocessing : 253 \n\nprocessing : 254 \n\nprocessing : 255 \n\nStart of epoch 0\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-2\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-2\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n","name":"stdout"},{"output_type":"stream","text":"(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-2\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-2\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-4\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-5\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-6\n(1, 4)\nthe model loss is :-3\nStart of epoch 1\nStart of epoch 2\nStart of epoch 3\nStart of epoch 4\nStart of epoch 5\nStart of epoch 6\nStart of epoch 7\nStart of epoch 8\nStart of epoch 9\n(1, 4)\n","name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-e5f4b538d5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-c0de00a59eb4>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactionNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriticalNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-ae0838a1d68e>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, observe, reward, epochs, batch, shuffle)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_observe_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpred_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_observe_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_reward_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the model loss is :%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-ae0838a1d68e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyActivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-b0e7f6d970fa>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;31m# not the last dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mbroadcast_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m     \u001b[0mbroadcast_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       if (v is not None and len(v.shape) != ndims and\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}